I wrote this code to evaluate the performance of a Classification Model. The performance of the model is evaluated using metrics such as Precision, Recall, F1-Score, and overall Accuracy for each class. This is usually done when the model has divided the data into several labels and we want to see how well the model's predictions match the actual data.

Code Goal:
Check the quality of a model's predictions.
Analyze the model's performance in each label separately.
Provide an overall measure of the model's accuracy.

With this work, I will show what operations are performed when a simple line of code is used using the library to perform the modeling process of accuracy and other criteria.

I'll also show you a picture of the output.
